{"headers": {
   "nav_date": "7/13/2017",
   "fund_id": "52Z5",
   "client_name": "51",
   "event_ts": "7/13/2017 16:06",
   "event_id": 30009,
   "processed_date": "7/13/2017",
   "event_ts_num": 0.671053241,
   "date_time": "7/13/2017 16:06",
   "event_time_numeric": 0.671053,
   "date_identifier": 1
 }},
 
 hive -e 'select '{"headers": ', named_struct(
 "nav_date", nav_date,
   "fund_id", fund_id,
   "client_name", client_name,
   "event_ts", event_ts,
   "event_id", event_id,
   "processed_date", processed_date,
   "event_ts_num", event_ts_num,
   "date_time", date_time,
   "event_time_numeric", event_time_numeric,
   "date_identifier", date_identifier ), '}'
 from h011gtcsandbox.pxo_myview_mtmi_1
 where substr(event_ts,9,5) >'16:00' and substr(event_ts,9,5)<='16:05';'
 | sed 's/[\t]//g' > /auto/users-04/p804670/pxo_myview_mtmi_2.csv
 
 -------------------------------------------------------

---------------Bar chart Query ----------
select distinct c.client_identifier, c.predicted, c.cumsum, c.error, coalesce(d.client_name, 'CLIENT MAPPING NOT FOUND') as client_name
from
(select client_identifier, predicted, cumsum, error
from
(select bin,
case
when sum(error)/sum(predicted) > 0.1
--when sum(error)/sum(predicted) < 0.1  --For testing
then 1 
else
 0 
end as flag
from h011gtcsandbox.test_mtmi_real_output 
where nav_date = to_date(now())
and bin = (select max(bin) from  h011gtcsandbox.test_mtmi_real_output where nav_date = to_date(now()))
group by bin
) a
join
h011gtcsandbox.test_mtmi_real_output b
on a.bin = b.bin
where nav_date = to_date(now()) and b.cumsum<b.predicted and a.flag= 1) c
left join
h011gtcsandbox.xnd_mtmi_client_info_merged d
on d.client_identifier = c.client_identifier
where c.error > 2
order by c.error desc limit 10
 
--------------------new table ---------------------
---> MTMI 
CREATE TABLE h011gtcsandbox.xnd_mtmi_client_info_merged (   
fund_id  VARCHAR(10),
client_identifier BIGINT,   
client_name VARCHAR(100))
STORED AS PARQUET 
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');

CREATE TABLE h011gtcsandbox.xnd_mtmi_client_Test(
fund_id  VARCHAR(10),
client_identifier BIGINT,   
client_name VARCHAR(100))
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE;


---> NAV

CREATE TABLE h011gtcsandbox.xnd_nav_client_info_merged (   
fund_id  VARCHAR(10),
Ticker   VARCHAR(10),
client_name VARCHAR(100),
client_identifier BIGINT)   
STORED AS PARQUET 
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');

CREATE TABLE h011gtcsandbox.xnd_nds_client_Test(
fund_id  VARCHAR(10),
Ticker   VARCHAR(10),
client_name VARCHAR(100),
client_identifier BIGINT)
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/BFDS_Additional_Funds_Masked_051319_1.txt' into table h011gtcsandbox.pxo_navnow_fund_client_mapping_3;


insert into table h011gtcsandbox.xnd_nds_client_info_merged
select * from h011gtcsandbox.xnd_nav_client_Test

-- > Pricing
CREATE TABLE h011gtcsandbox.xnd_Pricing_client_info_merged (   
client_identifier BIGINT,
client_name VARCHAR(100),
fund_id  VARCHAR(10)) 
STORED AS PARQUET 
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');

CREATE TABLE h011gtcsandbox.xnd_Pricing_client_Test(
client_identifier BIGINT,
client_name VARCHAR(100),
fund_id  VARCHAR(10))
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/Pricing_Mapping_v01.csv' into table h011gtcsandbox.xnd_Pricing_client_Test;


insert into table h011gtcsandbox.xnd_Pricing_client_info_merged
select * from h011gtcsandbox.xnd_Pricing_client_Test

-- > all
CREATE TABLE h011gtcsandbox.pxo_navnow_client_info(   
ticker VARCHAR(10),
fund_id  VARCHAR(10),
client_name VARCHAR(100)
) 
STORED AS PARQUET 
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');

CREATE TABLE h011gtcsandbox.pxo_navnow_client_info_Test(
ticker VARCHAR(10),
fund_id  VARCHAR(10),
client_name VARCHAR(100)
)
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/Mapped_funds_clients_masked.csv' into table h011gtcsandbox.pxo_navnow_client_info_Test;


insert into table h011gtcsandbox.pxo_navnow_client_info
select * from h011gtcsandbox.pxo_navnow_client_info_Test

----

\\wlbw4c002\SHARED\SQA_GRP\CTS - Process Excellence Office - PXO\Engagements\DataScience\XND\MTMI\results_08_23_18
--MTMI
create table h011gtcsandbox.mtmi_test_prediction(
Client_Identifier bigint, 
weekday		bigint,
Red_1		bigint,
Red_5 		bigint,
Red_10		bigint,
Red_20		bigint,
Predicted	bigint,
bin		    varchar(8))
stored as Parquet
location "/datalake/GTC_DATA/SANDBOX/h011gtcsandbox.db/XND/MTMI/test_prediction"
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');

ci_sys_updated_by                                 string,
ci_sys_updated_on                                 string
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES (
   "separatorChar" = ",",
   "quoteChar"     = "\"");


create table h011gtcsandbox.mtmi_test_Test(
Client_Identifier bigint,
weekday		bigint,
Red_1		bigint,
Red_5 		bigint,
Red_10		bigint,
Red_20		bigint,
Predicted	bigint,
bin		    varchar(8))
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/MTMI_Predicted_Results_merged_08282018.csv' into table h011gtcsandbox.mtmi_test_Test;


insert into table h011gtcsandbox.mtmi_test_prediction
select * from h011gtcsandbox.mtmi_test_Test


---NDS
create table h011gtcsandbox.nds_test_prediction(
Client_Identifier bigint,
weekday		bigint,
Red_1		bigint,
Red_5 		bigint,
Red_10		bigint,
Red_20		bigint,
Predicted	bigint,
bin		    varchar(8))
stored as Parquet
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');


create table h011gtcsandbox.nds_test_Test(
Client_Identifier bigint,
weekday		bigint,
Red_1		bigint,
Red_5 		bigint,
Red_10		bigint,
Red_20		bigint,
Predicted	bigint,
bin		    varchar(8))
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/Predicted_Results_NDS_08292018.csv' into table h011gtcsandbox.nds_test_Test;


insert into table h011gtcsandbox.nds_test_prediction
select * from h011gtcsandbox.nds_test_Test

---Pricing
create table h011gtcsandbox.Pricing_test_prediction(
Client_Identifier bigint,
weekday		bigint,
Red_1		bigint,
Red_5 		bigint,
Red_10		bigint,
Red_20		bigint,
Predicted	bigint,
bin		    varchar(8))
stored as Parquet
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');


create table h011gtcsandbox.Pricing_test_Test(
Client_Identifier bigint,
weekday		bigint,
Red_1		bigint,
Red_5 		bigint,
Red_10		bigint,
Red_20		bigint,
Predicted	bigint,
bin		    varchar(8))
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/Predicted_Results_Pricing_08292018.csv' into table h011gtcsandbox.Pricing_test_Test;

	insert into table h011gtcsandbox.Pricing_test_prediction
	select * from h011gtcsandbox.Pricing_test_Test

--------------------------------
insert into h011gtcsandbox.xnd_mtmi_client_level_result_5 
select 
client_identifier,
nav_date , 
weekday ,
mean_x,
mean_y,
cast('16:05:00' as varchar(8)),
8, 
predicted,
red_1, 
error,
abslute_error,
test
from h011gtcsandbox.xnd_mtmi_client_level_result_2
where bin = 1001

spark2-submit --master yarn --verbose --deploy-mode cluster --num-executors 4  mtmi_deployment.py

mtmi
create table h011pxo_m.pxo_myview_mtmi_client_info as select * from h011gtcsandbox.xnd_mtmi_client_info_merged;
create table h011pxo_m.pxo_myview_mtmi_predicated as select * from h011gtcsandbox.mtmi_test_prediction;
create table h011pxo_m.pxo_myview_mtmi_realtime like h011gtcsandbox.test_demo;

nds
create table h011pxo_m.pxo_nds_client_info as select * from h011gtcsandbox.xnd_nds_client_info_merged;
create table h011pxo_m.pxo_nds_predicated as select * from h011gtcsandbox.nds_test_prediction;
create table h011pxo_m.pxo_nds_realtime like h011gtcsandbox.nds_test_demo;


Pricing
create table h011pxo_m.pxo_myview_pricing_client_info as select * from h011gtcsandbox.xnd_pricing_client_info_merged;
create table h011pxo_m.pxo_myview_pricing_predicated as select * from h011gtcsandbox.pricing_test_prediction;
create table h011pxo_m.pxo_myview_pricing_realtime like h011gtcsandbox.pricing_test_demo;
-------new
mtmi

create table h011gtcsandbox.pxo_navnow_mtmi_client_info as select * from h011gtcsandbox.xnd_mtmi_client_info_merged;
create table h011gtcsandbox.pxo_navnow_mtmi_predicted as select * from h011gtcsandbox.mtmi_test_prediction;
create table h011gtcsandbox.pxo_navnow_mtmi_clientlevel like h011gtcsandbox.test_demo;

pricing
create table h011gtcsandbox.pxo_navnow_pricing_client_info as select * from h011gtcsandbox.xnd_pricing_client_info_merged;
create table h011gtcsandbox.pxo_navnow_pricing_predicted as select * from h011gtcsandbox.pricing_test_prediction;
create table h011gtcsandbox.pxo_navnow_pricing_clientlevel like h011gtcsandbox.pricing_test_demo;

nds:
create table h011gtcsandbox.pxo_navnow_nds_client_info as select * from h011gtcsandbox.xnd_nds_client_info_merged;
create table h011gtcsandbox.pxo_navnow_nds_predicted as select * from h011gtcsandbox.nds_test_prediction;
create table h011gtcsandbox.pxo_navnow_nds_clientlevel like h011gtcsandbox.nds_test_demo;


Dev------new
mtmi

create table h011pxo_m.pxo_navnow_mtmi_client_info as select * from h011pxo_m.pxo_myview_mtmi_client_info;
create table h011pxo_m.pxo_navnow_mtmi_predicted as select * from h011pxo_m.pxo_myview_mtmi_predicated;
create table h011pxo_m.pxo_navnow_mtmi_clientlevel like h011pxo_m.pxo_nds_realtime;

pricing
create table h011pxo_m.pxo_navnow_pricing_client_info as select * from h011pxo_m.pxo_myview_pricing_client_info;
create table h011pxo_m.pxo_navnow_pricing_predicted as select * from h011pxo_m.pxo_myview_pricing_predicated;
create table h011pxo_m.pxo_navnow_pricing_clientlevel like h011pxo_m.pxo_myview_pricing_realtime;

nds:
create table h011pxo_m.pxo_navnow_nds_client_info as select * from h011pxo_m.pxo_nds_client_info;
create table h011pxo_m.pxo_navnow_nds_predicted as select * from h011pxo_m.pxo_nds_predicated;
create table h011pxo_m.pxo_navnow_nds_clientlevel like h011pxo_m.pxo_nds_realtime;

beeline -u 'jdbc:hive2://gdch01d13:10000/default;principal=hive/gdch01d13@UATBDAKRB.COM' -e "create table h011pxo_m.pxo_navnow_mtmi_client_info as select * from h011pxo_m.pxo_myview_mtmi_client_info;"
beeline -u 'jdbc:hive2://gdch01d13:10000/default;principal=hive/gdch01d13@UATBDAKRB.COM' -e "create table h011pxo_m.pxo_navnow_mtmi_predicted as select * from h011pxo_m.pxo_myview_mtmi_predicated;"
beeline -u 'jdbc:hive2://gdch01d13:10000/default;principal=hive/gdch01d13@UATBDAKRB.COM' -e "create table h011pxo_m.pxo_navnow_mtmi_clientlevel like h011pxo_m.pxo_nds_realtime;"
beeline -u 'jdbc:hive2://gdch01d13:10000/default;principal=hive/gdch01d13@UATBDAKRB.COM' -e "create table h011pxo_m.pxo_navnow_pricing_client_info as select * from h011pxo_m.pxo_myview_pricing_client_info;"
beeline -u 'jdbc:hive2://gdch01d13:10000/default;principal=hive/gdch01d13@UATBDAKRB.COM' -e "create table h011pxo_m.pxo_navnow_pricing_predicted as select * from h011pxo_m.pxo_myview_pricing_predicated;"
beeline -u 'jdbc:hive2://gdch01d13:10000/default;principal=hive/gdch01d13@UATBDAKRB.COM' -e "create table h011pxo_m.pxo_navnow_pricing_clientlevel like h011pxo_m.pxo_myview_pricing_realtime;"
beeline -u 'jdbc:hive2://gdch01d13:10000/default;principal=hive/gdch01d13@UATBDAKRB.COM' -e "create table h011pxo_m.pxo_navnow_nds_client_info as select * from h011pxo_m.pxo_nds_client_info;"
beeline -u 'jdbc:hive2://gdch01d13:10000/default;principal=hive/gdch01d13@UATBDAKRB.COM' -e "create table h011pxo_m.pxo_navnow_nds_predicted as select * from h011pxo_m.pxo_nds_predicated;"
beeline -u 'jdbc:hive2://gdch01d13:10000/default;principal=hive/gdch01d13@UATBDAKRB.COM' -e "create table h011pxo_m.pxo_navnow_nds_clientlevel like h011pxo_m.pxo_nds_realtime;"

invalidate metadata h011gtcsandbox.pxo_navnow_mtmi_client_info;
invalidate metadata h011gtcsandbox.pxo_navnow_mtmi_predicted; 
invalidate metadata h011gtcsandbox.pxo_navnow_mtmi_clientlevel;
invalidate metadata h011gtcsandbox.pxo_navnow_pricing_client_info; 
invalidate metadata h011gtcsandbox.pxo_navnow_pricing_predicted;
invalidate metadata h011gtcsandbox.pxo_navnow_pricing_clientlevel ;
invalidate metadata h011gtcsandbox.pxo_navnow_nds_client_info ;
invalidate metadata h011gtcsandbox.pxo_navnow_nds_predicted ;
invalidate metadata h011gtcsandbox.pxo_navnow_nds_clientlevel;
invalidate metadata h011pxo_m.pxo_navnow_mtmi_client_info; 
invalidate metadata h011pxo_m.pxo_navnow_mtmi_predicted ;
invalidate metadata h011pxo_m.pxo_navnow_mtmi_clientlevel;
invalidate metadata h011pxo_m.pxo_navnow_pricing_client_info ;
invalidate metadata h011pxo_m.pxo_navnow_pricing_predicted ;
invalidate metadata h011pxo_m.pxo_navnow_pricing_clientlevel ;
invalidate metadata h011pxo_m.pxo_navnow_nds_client_info; 
invalidate metadata h011pxo_m.pxo_navnow_nds_predicted ;
invalidate metadata h011pxo_m.pxo_navnow_nds_clientlevel ;
-------------------------------------------------------------


select max(bin) from h011pxo_m.pxo_myview_mtmi_realtime
select bin, count(*) from h011pxo_m.pxo_myview_mtmi_realtime group by bin order by bin
select sum(cumsum) from h011pxo_m.pxo_myview_mtmi_realtime

Predicted

sdlgtcbak07542bdauat2

yarn application -kill application_1533420310509_17720
yarn application -kill application_1533420310509_17682


/auto/users-06/p642336/./nds_shell.sh


copy /auto/users-04/p804670/nav_now02.sh /usr/local/sdlgtcbak07542bdauat2/bin
copy /auto/users-04/p804670/nav_now03.sh /usr/local/sdlgtcbak07542bdauat2/bin

cd /usr/local/sdlgtcbak07542bdauat2/bin

mv itd_ddl.sh itd_ddl_1.sh
mv nav_now02.sh itd_ddl.sh

mv itd_ingestion.sh itd_ingestion_1.sh
mv nav_now03.sh itd_ingestion.sh

MTMI/Pricing:
NAV_DATE           
FUND_ID              
EVENT_TS            
Event_ID 
---
NDS:
AS_OF_DATE   
EVENT_ID    
FUND_ID  
TICKER     
SEND_TIME

--num-executors 6 --executor-cores 2   
--executor-memory 4G --driver-memory 2G

--mtmi
select bin,sum(predicted),sum(cumsum) from h011pxo_m.pxo_myview_mtmi_realtime where nav_date = current_date group by bin order by bin;

--pricing
select bin,sum(predicted),sum(cumsum) from h011pxo_m.pxo_myview_pricing_realtime where nav_date = current_date group by bin order by bin ;

--nds
select bin,sum(predicted),sum(cumsum) from h011pxo_m.pxo_nds_realtime where nav_date = current_date group by bin order by bin ;


------------------------------------------------Syed ---------------------------------------------------------
--mtmi
CREATE TABLE h011gtcsandbox.mtm_val_dummy(
NAV_DATE VARCHAR(10),
FUND_ID VARCHAR(10),
Client_Name VARCHAR(100),
EVENT_TS VARCHAR(20),
EVENT_ID VARCHAR(10),
Date_1 VARCHAR(10),
Event_TS_num VARCHAR(10),
DateTime_1 VARCHAR(20),
EVENT_TIME_NUMERIC double,
client_identifier BIGINT)
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/MTM_Val_dummy.csv' into table h011gtcsandbox.mtm_val_dummy;
------------
CREATE TABLE h011gtcsandbox.NDS_Client_Level_NAV_Delivery_3(
AS_OF_DATE VARCHAR(10),
Fund_Id VARCHAR(10),
Ticker VARCHAR(10),
SEND_TIME VARCHAR(20),
NASDAQ_ACK_TIME VARCHAR(20),
Date_1 VARCHAR(10),
Event_TS_num VARCHAR(10),
DateTime_1 VARCHAR(20),
EVENT_TIME_NUMERIC double,
Client_Name VARCHAR(100),
Date_Identifier BIGINT)
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/Client_Level_NAV_Delivery_3.csv' into table h011gtcsandbox.NDS_Client_Level_NAV_Delivery_3;


CREATE TABLE h011gtcsandbox.NDS_Client_Level_NAV_Delivery_4(
AS_OF_DATE VARCHAR(10),
Fund_Id VARCHAR(10),
Ticker VARCHAR(10),
SEND_TIME VARCHAR(20),
NASDAQ_ACK_TIME VARCHAR(20),
Date_1 VARCHAR(10),
Event_TS_num VARCHAR(10),
DateTime_1 VARCHAR(20),
EVENT_TIME_NUMERIC double,
Client_Name VARCHAR(100),
Date_Identifier BIGINT)
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/Ticker_raw_data_sep.csv' into table h011gtcsandbox.NDS_Client_Level_NAV_Delivery_4;

--pricing
CREATE TABLE h011gtcsandbox.Client_Level_Pricing_1_v03_SSHZ(
NAV_DATE VARCHAR(10),
FUND_ID VARCHAR(10),
Client_Name VARCHAR(100),
EVENT_TS VARCHAR(20),
EVENT_ID VARCHAR(10),
Date_1 VARCHAR(10),
Event_TS_num VARCHAR(10),
DateTime_1 VARCHAR(20),
EVENT_TIME_NUMERIC double,
Date_Identifier BIGINT)
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/Client_Level_Pricing_1_v03_SSHZ.csv' into table h011gtcsandbox.Client_Level_Pricing_1_v03_SSHZ;
------------


create table h011pxo_m.xnd_mtmi_client_info_merged as select * from h011gtcsandbox.xnd_mtmi_client_info_merged;
create table h011pxo_m.mtmi_test_prediction as select * from h011gtcsandbox.mtmi_test_prediction;

create table  h011pxo_m.mtmi_test_realtime like h011pxo_m.pxo_myview_mtmi_realtime location  '/datalake/PXO/MART/h011pxo_m.db/pxo_myview_mtmi_realtime'

FUND_ID,Client Name,Client_Identifier
---> Client Info MTMI

CREATE TABLE h011gtcsandbox.pxo_navnow_mtmi_client_info (   
fund_id  VARCHAR(10),
client_name VARCHAR(100),
client_identifier BIGINT)
STORED AS PARQUET 
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');

CREATE TABLE h011gtcsandbox.xnd_mtmi_client_Test(
fund_id  VARCHAR(10),
client_name VARCHAR(100),
client_identifier BIGINT)
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");;

load data local inpath '/auto/users-04/p804670/MTMI_Client_Mapping_10012018.csv' into table h011gtcsandbox.xnd_mtmi_client_Test;


insert into table h011gtcsandbox.pxo_navnow_mtmi_client_info
select * from h011gtcsandbox.xnd_mtmi_client_Test

---> Client Info Pricing 

CREATE TABLE h011gtcsandbox.pxo_navnow_pricing_client_info (   
client_identifier BIGINT,
client_name VARCHAR(100),
fund_id  VARCHAR(10))
STORED AS PARQUET 
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');

CREATE TABLE h011gtcsandbox.xnd_pricing_client_Test(
client_identifier BIGINT,
client_name VARCHAR(100),
fund_id  VARCHAR(10))
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");

load data local inpath '/auto/users-04/p804670/.csv' into table h011gtcsandbox.xnd_pricing_client_Test;

insert into table h011gtcsandbox.pxo_navnow_pricing_client_info
select *  from h011gtcsandbox.xnd_pricing_client_Test
-------

---> Client Info Pricing 


 --- with array ----
CREATE TABLE h011gtcsandbox.pxo_navnow_client_fund_cache_array (
	client_name string,
	fund_id array<string>,
	data_category string,
	as_of_tms timestamp
	)
PARTITIONED BY (nav_date string)
STORED AS PARQUET
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');
		
	insert into table h011gtcsandbox.pxo_navnow_client_fund_cache_array partition(nav_date)
	VALUES ('dummy_client',array('fundid1','fundid2'),'dummy_category', now(), to_date(now()))

--in hive
insert into table h011gtcsandbox.pxo_navnow_client_fund_cache_array partition(nav_date)
select 'dummy_client',array('fundid1','fundid2') ,'dummy_category', current_timestamp(), current_date()

create table h011pxo_sbx_navnow_m.pxo_navnow_mtmi_predicted as select * from h011pxo_m.pxo_navnow_mtmi_predicted;

invalidate metadata h011pxo_sbx_navnow_m.pxo_navnow_pricing_clientlevel ;

select a.bin, a.signal, coalesce(b.cumsum, 0) as cumsum, coalesce(c.predicted,0) as predicted, coalesce((c.predicted-b.cumsum),0) as red_1 from(
with signal as (
select coalesce(a.s,b.s,c.s) as signal, 1 as f from
(select 'NASDAQ' as s, 1 as f) a
full outer join
(select 'BFDS' as s, 2 as f) b
on a.s=b.s
full outer join
(select 'BOTH' as s, 3 as f) c
on b.s=c.s)
select bin,signal from 
(select bin, 1 as f2
from h011pxo_m.pxo_navnow_mtmi_predicted
where substr(bin,4,2) in ('00','05','10','15','20','25','30','35','40','45','50','55')
group by bin) t, signal where f=f2) a
left join (
select cnt, bin, signal, sum(cnt) over (partition by signal order by bin) as cumsum from
(select from_unixtime(hour(cast(actual_completion_time as string))*3600+300+MINUTE(cast(actual_completion_time as string))*60-(((MINUTE(cast(actual_completion_time as string))*60) %300)), 'HH:mm:ss') as bin,
count(fund_id) as cnt, signal from h011pxo_m.pxo_navnow_mtmi_fundlevel 
where nav_date = to_date(now()) and actual_completion_time !='NA' 
group by signal, bin ) t ) b 
on a.bin=b.bin and a.signal=b.signal
left join(
select cnt, bin, signal, sum(cnt) over (partition by signal order by bin) as predicted from
(select from_unixtime(hour(cast(predicted_time as string))*3600+300+MINUTE(cast(predicted_time as string))*60-(((MINUTE(cast(predicted_time as string))*60) %300)), 'HH:mm:ss') as bin,
count(fund_id) as cnt, signal from h011pxo_m.pxo_navnow_mtmi_funds_predicted group by signal, bin) t ) c
on a.bin=c.bin and a.signal=c.signal
order by a.bin

 CREATE TABLE h011gtcsandbox.pxo_navnow_client_name_id_mapping_stg(
client_name string,
client_name_num int
)
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as TEXTFILE
tblproperties ("skip.header.line.count"="1");


load data local inpath '/users/users-04/p804670/Client_name_number_mapping_2.txt' INTO TABLE h011gtcsandbox.pxo_navnow_client_name_id_mapping_stg;


CREATE TABLE h011gtcsandbox.pxo_navnow_client_name_id_mapping(
client_name string,
client_name_num int
)
STORED AS PARQUET
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');

set hive.execution.engine=mr;

outset number
set nonumber
\\ntfa0009\ITD-Shared\Temp\anoop
 \\mf_a3e_01\DEVinstalls\Standard_Tools_Share
\\mfjabp02\OHD-01-Printer1
\\gdcpw4633 - print

\\wlbw4c002\shared\SQA_GRP\CTS - Process Excellence Office - PXO\Engagements\START

(after access we need to restart our system)

vi
klist
kdestroy
state <file_name>
over write file at HDFS:
fc - hstory of command executed
hadoop fs -copyFromLocal -f <localfile> <hdfsDir>
https://cloud.statestr.com/navnow/

show databases like  '*h011pxo_m*';
show tables  '*navnow*';

pkill -u p804670
pbrun checkuser -u p804670
HUE DEV/UAT2:
https://gdch01d13.statestr.com:8888/hue/home/
HUE PROD:
https://gdch02d04:8888/hue/editor/?type=hive

!pip install plotlyp80467p

verify if Kudu and Impala are running:
$ ps aux | grep kudu
$ ps aux | grep impalad
https://kudu.apache.org/docs/quickstart.html
https://kudu.apache.org/docs/schema_design.html

compute stats big_strings;
show column stats big_strings;

/opt/cloudera/parcels/CDH-5.13.1-1.cdh5.13.1.p0.2/lib
/opt/cloudera/parcels/STREAMSETS_DATACOLLECTOR-3.2.0.0

hostname -i



/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2/conf/spark-defaults.conf
hbase shell
yarn application -kill application_1533420310509_17725

yarn application -list
-----
impala-shell
connect impala-uat2.statestr.com;
show current roles;
show grant role gtcbdap_role 

mapred job  -list

show locks extended;

https://rtcprod.statestr.com/ccm3
click on GTC->build-->gtc_model_certDistribute

pbrun checkuser -U e661445

/opt/cloudera/parcels/SPARK2/lib/spark2/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py


!connect jdbc:hive2://gdch01d13.statestr.com:10000/default;principal=hive/_HOST@UATBDAKRB.COM

outset number
set nonumber

cat /usr/local/sulpauxnd14089/logs/nds_One_Min_Job_log_2018-10-31.log | grep 'Number Of Flume Event Sent:' |sed 's/[a-z,A-Z]//g'|sed 's/-->//g' > nds_uat_2018-10-31.txt

cat /usr/local/sulpauxnd14089sys/logs/nds_One_Min_Job_log_2018-10-31.log | grep 'Number Of Flume Event Sent:' |sed 's/[a-z,A-Z]//g'|sed 's/-->//g' > nds_uat2_2018-10-31.txt

export FLAGS="-Djavax.net.ssl.trustStore=/usr/local/admin/uat2_certs/gdch01-cluster02.truststore"
export OOZIE_URL=https://gdch01d13.statestr.com:11443/oozie
oozie $FLAGS job $OOZIE_URL -config hivejob.properties -run


user.name=p800184
jobTracker=yarnRM
nameNode=hdfs://gdch01-cluster02-ns

oozie.libpath = /user/oozie/share/lib
oozie.wf.application.path=hdfs://gdch01-cluster02-ns/user/p800184/hdfs_hive
oozie.use.system.libpath=true


--connect jdbc:oracle:thin:@dgns01:1525:O01GNS1 --username p521516 --password pass0512

